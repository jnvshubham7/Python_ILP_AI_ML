{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d07ef-4712-45a6-83f5-9ae0396b7f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example dataset\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]  # Features\n",
    "y = [0, 1, 0, 1, 0]  # Labels\n",
    "\n",
    "# Split into Train and Temp (CV + Test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Split Temp into CV and Test\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Training set:\", X_train, y_train)\n",
    "print(\"Cross-Validation set:\", X_cv, y_cv)\n",
    "print(\"Test set:\", X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40fb15-52c1-4825-909c-f948cd4b2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "print(data)\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Decision Tree classifier\n",
    "tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Visualize the tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(tree, feature_names=data.feature_names, class_names=data.target_names, filled=True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66218e26-b577-442b-a93a-a10d5c46237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('car.csv')\n",
    "\n",
    "df.isnull().sum()\n",
    "df.fillna(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sns.boxplot(df['vehicle_age'])\n",
    "\n",
    "# # EDA: Summary statistics\n",
    "# print(df.info())\n",
    "# print(df.describe())\n",
    "\n",
    "# # Visualize distribution\n",
    "# df['car_name'].hist()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # Handle missing values\n",
    "# df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# # Encode categorical data\n",
    "# df_encoded = pd.get_dummies(df['category_column'])\n",
    "\n",
    "# # Feature scaling\n",
    "# scaler = StandardScaler()\n",
    "# df_scaled = scaler.fit_transform(df[['brand', 'model']])\n",
    "\n",
    "# # Train-Test Split\n",
    "# X = df[['brand', 'model']]\n",
    "# y = df['fuel_type']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(\"Training set size:\", len(X_train))\n",
    "# print(\"Test set size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc7f97-29fb-4ba0-97cb-406ac5cb8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c982f2-9196-411c-9a52-800262c7d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "df['z_score'] = zscore(df['vehicle_age'])\n",
    "df_outliers = df[df['z_score'].abs() > 3]\n",
    "\n",
    "print(df_outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4768215-9816-4122-8799-3a751c1686b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283987a-7b77-496d-8d6c-e7c7868c5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9554e535-814b-4e8e-981b-8ac10a4fdf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['brand'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6afc42-ca45-4413-8eac-db0ce7647e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a14337-26b6-4215-87b4-1c84bec4c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(numeric_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9287c7a-c018-49be-995a-4d00bc0d932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('car.csv')  # Replace with your actual file path\n",
    "print(\"Initial dataset shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Handle missing values with KNN Imputer (for numeric columns only)\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df[numeric_columns] = pd.DataFrame(imputer.fit_transform(df[numeric_columns]), columns=numeric_columns)\n",
    "\n",
    "# Detect and treat outliers for 'selling_price' (as an example)\n",
    "Q1 = df['selling_price'].quantile(0.25)\n",
    "Q3 = df['selling_price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df['selling_price'] = df['selling_price'].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "# Encode all categorical variables\n",
    "categorical_columns = ['car_name', 'brand', 'model', 'seller_type', 'fuel_type', 'transmission_type']\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "print(\"Shape after encoding categorical variables:\", df_encoded.shape)\n",
    "print(df_encoded.head())\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df_encoded.drop(columns=['selling_price']))  # Features\n",
    "scaled_target = scaler.fit_transform(df_encoded[['selling_price']])  # Target (assuming it's numeric)\n",
    "\n",
    "# Combine scaled features and target\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=df_encoded.drop(columns=['selling_price']).columns)\n",
    "df_scaled['selling_price'] = scaled_target\n",
    "print(\"Shape after scaling:\", df_scaled.shape)\n",
    "print(df_scaled.head())\n",
    "\n",
    "# Train-test split\n",
    "X = df_scaled.drop(columns=['selling_price']).values  # Features\n",
    "y = df_scaled['selling_price'].values  # Target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualize correlation of the training set\n",
    "print(\"Rendering heatmap...\")\n",
    "sns.heatmap(pd.DataFrame(X_train, columns=df_encoded.drop(columns=['selling_price']).columns).corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# Final dataset preview\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b2622-dfc8-4efe-80db-34579f8a2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(data)\n",
    "\n",
    "\n",
    "print(iris)\n",
    "\n",
    "# # Create a DataFrame for visualization\n",
    "# pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "# pca_df['Target'] = iris.target\n",
    "\n",
    "# # Plot the PCA result\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# for label in pca_df['Target'].unique():\n",
    "#     subset = pca_df[pca_df['Target'] == label]\n",
    "#     plt.scatter(subset['PC1'], subset['PC2'], label=iris.target_names[label])\n",
    "# plt.xlabel('Principal Component 1')\n",
    "# plt.ylabel('Principal Component 2')\n",
    "# plt.title('PCA on Iris Dataset')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064943dc-2c30-4b0f-a4a5-5005bc4caeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "import numpy as np\n",
    "\n",
    "# Create a toy dataset (mixture of signals)\n",
    "np.random.seed(42)\n",
    "s1 = np.sin(2 * np.pi * np.linspace(0, 1, 1000))  # Signal 1: sine wave\n",
    "s2 = np.sign(np.sin(3 * np.pi * np.linspace(0, 1, 1000)))  # Signal 2: square wave\n",
    "S = np.c_[s1, s2]\n",
    "S += 0.2 * np.random.normal(size=S.shape)  # Add noise\n",
    "\n",
    "# Mix the signals\n",
    "A = np.array([[1, 1], [0.5, 2]])  # Mixing matrix\n",
    "X = S.dot(A.T)  # Mixed signals\n",
    "\n",
    "# Apply ICA\n",
    "ica = FastICA(n_components=2, random_state=42)\n",
    "S_ica = ica.fit_transform(X)  # Reconstructed signals\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title(\"Original Signals\")\n",
    "plt.plot(S)\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title(\"Mixed Signals\")\n",
    "plt.plot(X)\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title(\"Reconstructed Signals (ICA)\")\n",
    "plt.plot(S_ica)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c7701-a6a1-49a6-88b0-52ec14cbed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "X = np.array([[1], [2], [3], [4], [5]])  # Independent variable\n",
    "y = np.array([3, 6, 7, 8, 11])          # Dependent variable\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict([[15]])\n",
    "print(f\"Prediction for X=6: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c587f7-3310-4d70-ad2e-9da853248834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Data\n",
    "X = np.array([[1], [2], [3], [4], [5]])  # Independent variable\n",
    "y = np.array([3, 6, 7, 8, 11])          # Dependent variable\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "X_range = np.linspace(1, 6, 100).reshape(-1, 1)\n",
    "y_pred = model.predict(X_range)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X_range, y_pred, color='red', label='Regression Line')\n",
    "plt.title('Linear Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91d6a4-a4bf-4798-b942-2110ca3349c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Data\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([2, 5, 10, 17, 26])\n",
    "\n",
    "# Transform features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "\n",
    "print(f\"prediction of this model {model.predict(poly.transform([[6]]))} \")\n",
    "\n",
    "# Predictions\n",
    "X_range = np.linspace(1, 6, 100).reshape(-1, 1)\n",
    "y_pred = model.predict(poly.transform(X_range))\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X_range, y_pred, color='red', label='Polynomial Fit')\n",
    "plt.title('Polynomial Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b5e34d3-a2a8-4eea-857c-7a00e9252d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = np.array([[1], [2], [3], [4], [5]])  # Independent variable\n",
    "y = np.array([3, 6, 7, 8, 11])          # Dependent variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56658b46-0a61-48de-8ebb-4921d9cb5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=3)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict([[6]])\n",
    "print(f\"Prediction for X=6: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f285b15-7c0a-400d-90fa-b03fe554b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict([[6]])\n",
    "print(f\"Prediction for X=6: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1006f3d1-a674-42dc-836f-debdc025444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict([[6]])\n",
    "print(f\"Prediction for X=6: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a164ce-e9aa-4335-9903-d745ea1bab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR(kernel='rbf')\n",
    "model.fit(X, y)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict([[6]])\n",
    "print(f\"Prediction for X=6: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60592f-62d7-48aa-985b-45c872b8e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Data\n",
    "X = np.array([[1], [2], [3], [4], [5]])  # Independent variable\n",
    "y = np.array([3, 6, 7, 8, 11])          # Dependent variable\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "X_range = np.linspace(1, 6, 100).reshape(-1, 1)\n",
    "y_pred = model.predict(X_range)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X_range, y_pred, color='red', label='Regression Line')\n",
    "plt.title('Linear Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f6dd2-925a-40fa-8d89-95abadc14116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Data\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([2, 5, 10, 17, 26])\n",
    "\n",
    "# Transform features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "\n",
    "# Predictions\n",
    "X_range = np.linspace(1, 6, 100).reshape(-1, 1)\n",
    "y_pred = model.predict(poly.transform(X_range))\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X_range, y_pred, color='red', label='Polynomial Fit')\n",
    "plt.title('Polynomial Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1432c-7045-497e-8b83-ac3c112d8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Model\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_range)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X_range, y_pred, color='red', label='Ridge Regression')\n",
    "plt.title('Ridge Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d80fe42-c2ed-408b-8ccd-88ddf21632bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Model\n",
    "model = KNeighborsRegressor(n_neighbors=3)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_range)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X_range, y_pred, color='red', label='kNN Regression')\n",
    "plt.title('kNN Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76ef1a-02e7-4cb6-92ba-41a2fa04ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Model\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_range)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X_range, y_pred, color='red', label='Decision Tree Fit')\n",
    "plt.title('Decision Tree Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163380cd-b08f-4dc8-9468-776cdca1fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Example Data (Replace with your data)\n",
    "X = np.random.rand(100, 1) * 10  # 100 data points between 0 and 10\n",
    "y = np.sin(X).ravel() + np.random.normal(0, 0.1, 100)  # Sinusoidal data with noise\n",
    "\n",
    "# Model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "X_range = np.linspace(0, 10, 500).reshape(-1, 1)  # Smooth range for predictions\n",
    "y_pred = model.predict(X_range)\n",
    "\n",
    "# Model Score\n",
    "r2 = model.score(X, y)  # R² score on training data\n",
    "print(f\"R² Score: {r2}\")\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X_range, y_pred, color='red', label='Random Forest Fit')\n",
    "plt.title('Random Forest Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff25239b-41b3-45d5-b789-2f8ebe729c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Model\n",
    "model = SVR(kernel='rbf')\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_range)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X_range, y_pred, color='red', label='SVR Fit')\n",
    "plt.title('Support Vector Regression (SVR)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de42d306-d36d-4a6f-9968-57b62ef5398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=200, n_features=2, n_informative=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, random_state=42\n",
    ")\n",
    "\n",
    "# print(X, y)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create and fit the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Plotting the decision boundary\n",
    "def plot_decision_boundary(X, y, model):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.coolwarm)\n",
    "    plt.title(\"Logistic Regression Decision Boundary\")\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the decision boundary\n",
    "plot_decision_boundary(X, y, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d0ef3-3daf-4b06-91f0-dab73920e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "# iris.head()\n",
    "\n",
    "print(iris)\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train a logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f600e2-d5bd-4860-8610-593de08dc8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31597c-8a7d-4910-bf02-9327007de059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3e802-5639-4b69-a6a7-826604f5517e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
